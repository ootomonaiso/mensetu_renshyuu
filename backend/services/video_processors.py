"""
å‹•ç”»å‡¦ç†å°‚ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰

MediaPipe ã‚’ä½¿ã£ãŸéª¨æ ¼æ¤œå‡ºãƒ»å§¿å‹¢åˆ†æ
"""
import asyncio
import logging
import numpy as np
from typing import Dict, Any, Optional, Tuple
import cv2
import base64

logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_pose_detector = None
_face_mesh_detector = None
_mediapipe_import_failed = False  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—ãƒ•ãƒ©ã‚°


class PoseAnalyzer:
    """å§¿å‹¢åˆ†æãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆMediaPipe Poseï¼‰"""
    
    def __init__(self):
        self.pose = None
        
    async def initialize(self):
        """MediaPipe Pose ã‚’åˆæœŸåŒ–"""
        global _pose_detector, _mediapipe_import_failed
        if _pose_detector is None and not _mediapipe_import_failed:
            try:
                import mediapipe as mp
                logger.info("MediaPipe Pose ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
                _pose_detector = mp.solutions.pose.Pose(
                    static_image_mode=False,
                    model_complexity=1,
                    smooth_landmarks=True,
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5
                )
                logger.info("MediaPipe Pose ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except ImportError:
                if not _mediapipe_import_failed:
                    logger.warning("MediaPipe ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å§¿å‹¢åˆ†æã¯ç„¡åŠ¹ã§ã™ã€‚")
                    logger.info("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•: pip install mediapipe (Python 3.12ä»¥ä¸‹ãŒå¿…è¦)")
                    _mediapipe_import_failed = True
                _pose_detector = None
            except Exception as e:
                logger.warning(f"MediaPipe Pose ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
                _pose_detector = None
        self.pose = _pose_detector
        
    async def analyze(self, frame_data: bytes) -> Dict[str, Any]:
        """
        æ˜ åƒãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å§¿å‹¢ã‚’åˆ†æ
        
        Args:
            frame_data: JPEGç”»åƒãƒã‚¤ãƒŠãƒª
            
        Returns:
            å§¿å‹¢ã‚¹ã‚³ã‚¢ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ + ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒ
        """
        if self.pose is None:
            await self.initialize()
            if self.pose is None:
                return self._default_posture()
        
        try:
            # JPEG â†’ numpy array
            nparr = np.frombuffer(frame_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return self._default_posture()
            
            # RGBå¤‰æ›
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # MediaPipe ã§å‡¦ç†
            results = await asyncio.to_thread(self.pose.process, image_rgb)
            
            if not results.pose_landmarks:
                return {
                    "score": 50,
                    "feedback": "å§¿å‹¢ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    "details": {},
                    "overlay_image": None
                }
            
            # éª¨æ ¼ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»
            overlay_image = self._draw_pose_overlay(image.copy(), results)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            _, buffer = cv2.imencode('.jpg', overlay_image, [cv2.IMWRITE_JPEG_QUALITY, 80])
            overlay_base64 = base64.b64encode(buffer).decode('utf-8')
            
            
            # éª¨æ ¼ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»
            overlay_image = self._draw_pose_overlay(image.copy(), results)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            _, buffer = cv2.imencode('.jpg', overlay_image, [cv2.IMWRITE_JPEG_QUALITY, 80])
            overlay_base64 = base64.b64encode(buffer).decode('utf-8')
            
            # éª¨æ ¼ã‹ã‚‰å§¿å‹¢ã‚’è©•ä¾¡
            landmarks = results.pose_landmarks.landmark
            
            # è‚©ã®æ°´å¹³åº¦ãƒã‚§ãƒƒã‚¯
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            shoulder_angle = abs(left_shoulder.y - right_shoulder.y)
            
            # èƒŒç­‹ã®çœŸã£ã™ãã•ãƒã‚§ãƒƒã‚¯
            nose = landmarks[0]
            left_hip = landmarks[23]
            spine_alignment = abs(nose.x - left_hip.x)
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—
            score = 100
            feedback_parts = []
            
            if shoulder_angle > 0.05:
                score -= 20
                feedback_parts.append("è‚©ãŒå‚¾ã„ã¦ã„ã¾ã™")
            
            if spine_alignment > 0.1:
                score -= 15
                feedback_parts.append("èƒŒç­‹ã‚’ä¼¸ã°ã—ã¾ã—ã‚‡ã†")
            
            # é¡”ã®ä½ç½®ãƒã‚§ãƒƒã‚¯ï¼ˆå‰å‚¾ãƒ»å¾Œå‚¾ï¼‰
            if nose.z > 0:
                score -= 10
                feedback_parts.append("ã‚„ã‚„å‰å‚¾å§¿å‹¢ã§ã™")
            
            score = max(0, min(100, score))
            
            if score >= 80:
                feedback = "âœ¨ å§¿å‹¢ãŒè‰¯å¥½ã§ã™ï¼"
            elif score >= 60:
                feedback = "ğŸ‘ ã¾ãšã¾ãšã®å§¿å‹¢ã§ã™ã€‚" + ("ã€".join(feedback_parts) if feedback_parts else "")
            else:
                feedback = "ğŸ’¡ å§¿å‹¢ã‚’æ”¹å–„ã—ã¾ã—ã‚‡ã†: " + "ã€".join(feedback_parts)
            
            return {
                "score": int(score),
                "feedback": feedback,
                "details": {
                    "shoulder_level": float(1 - shoulder_angle * 10),
                    "spine_alignment": float(1 - spine_alignment * 5),
                    "forward_lean": float(-nose.z) if nose.z < 0 else 0.0
                },
                "overlay_image": overlay_base64
            }
            
        except Exception as e:
            logger.warning(f"å§¿å‹¢åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._default_posture()
    
    def _draw_pose_overlay(self, image: np.ndarray, results) -> np.ndarray:
        """éª¨æ ¼ç·šã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»"""
        try:
            import mediapipe as mp
            mp_drawing = mp.solutions.drawing_utils
            mp_pose = mp.solutions.pose
            
            # MediaPipe ã®æ¨™æº–æç”»
            mp_drawing.draw_landmarks(
                image,
                results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=mp_drawing.DrawingSpec(
                    color=(0, 255, 0), thickness=2, circle_radius=3
                ),
                connection_drawing_spec=mp_drawing.DrawingSpec(
                    color=(0, 255, 255), thickness=2
                )
            )
            
            # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸè‰²ä»˜ã‘ãƒã‚¤ãƒ³ãƒˆ
            landmarks = results.pose_landmarks.landmark
            h, w, _ = image.shape
            
            # è‚©ã®ãƒ©ã‚¤ãƒ³ã‚’å¼·èª¿
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            cv2.line(
                image,
                (int(left_shoulder.x * w), int(left_shoulder.y * h)),
                (int(right_shoulder.x * w), int(right_shoulder.y * h)),
                (255, 0, 0), 3
            )
            
            return image
        except Exception as e:
            logger.warning(f"æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def _default_posture(self) -> Dict[str, Any]:
        return {
            "score": 75,
            "feedback": "å§¿å‹¢åˆ†æä¸­...",
            "details": {},
            "overlay_image": None
        }


class EyeContactAnalyzer:
    """è¦–ç·šåˆ†æãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆMediaPipe Face Meshï¼‰"""
    
    def __init__(self):
        self.face_mesh = None
        
    async def initialize(self):
        """MediaPipe Face Mesh ã‚’åˆæœŸåŒ–"""
        global _face_mesh_detector, _mediapipe_import_failed
        if _face_mesh_detector is None and not _mediapipe_import_failed:
            try:
                import mediapipe as mp
                logger.info("MediaPipe Face Mesh ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
                _face_mesh_detector = mp.solutions.face_mesh.FaceMesh(
                    static_image_mode=False,
                    max_num_faces=1,
                    refine_landmarks=True,
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5
                )
                logger.info("MediaPipe Face Mesh ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            except ImportError:
                if not _mediapipe_import_failed:
                    logger.warning("MediaPipe ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¦–ç·šåˆ†æã¯ç„¡åŠ¹ã§ã™ã€‚")
                    _mediapipe_import_failed = True
                _face_mesh_detector = None
            except Exception as e:
                logger.warning(f"MediaPipe Face Mesh ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
                _face_mesh_detector = None
        self.face_mesh = _face_mesh_detector
        
    async def analyze(self, frame_data: bytes) -> Dict[str, Any]:
        """
        æ˜ åƒãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰è¦–ç·šã‚’åˆ†æ
        
        Args:
            frame_data: JPEGç”»åƒãƒã‚¤ãƒŠãƒª
            
        Returns:
            è¦–ç·šã‚¹ã‚³ã‚¢ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ + ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒ
        """
        if self.face_mesh is None:
            await self.initialize()
            if self.face_mesh is None:
                return self._default_eye_contact()
        
        try:
            # JPEG â†’ numpy array
            nparr = np.frombuffer(frame_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return self._default_eye_contact()
            
            # RGBå¤‰æ›
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # MediaPipe ã§å‡¦ç†
            results = await asyncio.to_thread(self.face_mesh.process, image_rgb)
            
            if not results.multi_face_landmarks:
                return {
                    "score": 50,
                    "feedback": "é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    "details": {},
                    "overlay_image": None
                }
            
            # é¡”ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»
            overlay_image = self._draw_face_overlay(image.copy(), results)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            _, buffer = cv2.imencode('.jpg', overlay_image, [cv2.IMWRITE_JPEG_QUALITY, 80])
            overlay_base64 = base64.b64encode(buffer).decode('utf-8')
            
            
            # é¡”ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»
            overlay_image = self._draw_face_overlay(image.copy(), results)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            _, buffer = cv2.imencode('.jpg', overlay_image, [cv2.IMWRITE_JPEG_QUALITY, 80])
            overlay_base64 = base64.b64encode(buffer).decode('utf-8')
            
            # è™¹å½©ã®ä½ç½®ã‹ã‚‰è¦–ç·šæ–¹å‘ã‚’æ¨å®š
            landmarks = results.multi_face_landmarks[0].landmark
            
            # å·¦ç›®ãƒ»å³ç›®ã®è™¹å½©ä½ç½®
            left_iris = landmarks[468]  # MediaPipe ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            right_iris = landmarks[473]
            
            # ç›®ã®ä¸­å¿ƒã‹ã‚‰ã®ã‚ºãƒ¬ã‚’è¨ˆç®—
            left_eye_center = landmarks[33]
            right_eye_center = landmarks[263]
            
            left_offset = abs(left_iris.x - left_eye_center.x)
            right_offset = abs(right_iris.x - right_eye_center.x)
            
            avg_offset = (left_offset + right_offset) / 2
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚«ãƒ¡ãƒ©ã‚’è¦‹ã¦ã„ã‚‹ã»ã©é«˜ã„ï¼‰
            score = max(0, min(100, int((1 - avg_offset * 5) * 100)))
            
            if score >= 80:
                feedback = "ğŸ‘ï¸ ã‚«ãƒ¡ãƒ©ã‚’ã—ã£ã‹ã‚Šè¦‹ã¦ã„ã¾ã™"
            elif score >= 60:
                feedback = "ğŸ‘€ ã»ã¼ã‚«ãƒ¡ãƒ©ã‚’è¦‹ã¦ã„ã¾ã™"
            else:
                feedback = "ğŸ’¡ ã‚«ãƒ¡ãƒ©ã‚’è¦‹ã‚‹ã‚ˆã†æ„è­˜ã—ã¾ã—ã‚‡ã†"
            
            return {
                "score": score,
                "feedback": feedback,
                "details": {
                    "gaze_offset": float(avg_offset),
                    "looking_away": avg_offset > 0.2
                },
                "overlay_image": overlay_base64
            }
            
        except Exception as e:
            logger.warning(f"è¦–ç·šåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._default_eye_contact()
    
    def _draw_face_overlay(self, image: np.ndarray, results) -> np.ndarray:
        """é¡”ãƒ¡ãƒƒã‚·ãƒ¥ã¨è¦–ç·šã‚¬ã‚¤ãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”»"""
        try:
            import mediapipe as mp
            mp_drawing = mp.solutions.drawing_utils
            mp_face_mesh = mp.solutions.face_mesh
            
            # é¡”ãƒ¡ãƒƒã‚·ãƒ¥ã®æç”»ï¼ˆç›®ã¨å£å‘¨ã‚Šã®ã¿ï¼‰
            mp_drawing.draw_landmarks(
                image,
                results.multi_face_landmarks[0],
                mp_face_mesh.FACEMESH_IRISES,  # è™¹å½©
                landmark_drawing_spec=mp_drawing.DrawingSpec(
                    color=(0, 255, 0), thickness=1, circle_radius=1
                ),
                connection_drawing_spec=mp_drawing.DrawingSpec(
                    color=(0, 255, 0), thickness=1
                )
            )
            
            # è¦–ç·šæ–¹å‘ã®çŸ¢å°ã‚’æç”»
            landmarks = results.multi_face_landmarks[0].landmark
            h, w, _ = image.shape
            
            # å·¦ç›®ã¨å³ç›®ã®ä¸­å¿ƒ
            left_iris = landmarks[468]
            right_iris = landmarks[473]
            
            left_x, left_y = int(left_iris.x * w), int(left_iris.y * h)
            right_x, right_y = int(right_iris.x * w), int(right_iris.y * h)
            
            # è™¹å½©ã‚’å¼·èª¿
            cv2.circle(image, (left_x, left_y), 3, (255, 0, 0), -1)
            cv2.circle(image, (right_x, right_y), 3, (255, 0, 0), -1)
            
            return image
        except Exception as e:
            logger.warning(f"æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def _default_eye_contact(self) -> Dict[str, Any]:
        return {
            "score": 70,
            "feedback": "è¦–ç·šåˆ†æä¸­...",
            "details": {},
            "overlay_image": None
        }
