"""
é¢æ¥ç·´ç¿’ã‚·ã‚¹ãƒ†ãƒ  - FastAPI ã‚µãƒ¼ãƒãƒ¼

éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ åˆ†æ â†’ Markdown ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""
from fastapi import FastAPI, File, UploadFile, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pathlib import Path
import logging
from datetime import datetime
from typing import Dict, Any, Optional
import os
import asyncio
import json
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ (backend/.env ã‚’å„ªå…ˆ)
load_dotenv(dotenv_path=Path(__file__).parent / ".env")

from backend.services.transcription import transcribe_audio
from backend.services.audio_analysis import analyze_audio_features
from backend.services.ai_analysis import analyze_with_gemini
from backend.services.report import generate_markdown_report
from backend.services.voice_emotion import analyze_voice_emotion, get_emotion_feedback
from backend.services.realtime_transcription import RealtimeTranscriber
from backend.services.video_analysis import analyze_video
from backend.services.realtime_analyzer import RealtimeAnalyzer
from backend.services.session_recorder import SessionRecorder
from backend.services.post_session_pipeline import run_post_session_pipeline

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPI ã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = FastAPI(
    title="åœ§å‹é¢æ¥ç·´ç¿’ã‚·ã‚¹ãƒ†ãƒ ",
    description="éŸ³å£°åˆ†æ â†’ AI è©•ä¾¡ â†’ Markdown ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ",
    version="1.0.0"
)

# CORS è¨­å®š (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],  # Vite/React é–‹ç™ºã‚µãƒ¼ãƒãƒ¼
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
OUTPUT_DIR = Path("output")
AUDIO_DIR = OUTPUT_DIR / "audio"
REPORTS_DIR = OUTPUT_DIR / "reports"
VIDEO_DIR = OUTPUT_DIR / "videos"
SESSIONS_DIR = OUTPUT_DIR / "sessions"
STATIC_DIR = Path("backend/static")

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
AUDIO_DIR.mkdir(parents=True, exist_ok=True)
REPORTS_DIR.mkdir(parents=True, exist_ok=True)
VIDEO_DIR.mkdir(parents=True, exist_ok=True)
SESSIONS_DIR.mkdir(parents=True, exist_ok=True)
STATIC_DIR.mkdir(parents=True, exist_ok=True)

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")
app.mount("/reports", StaticFiles(directory=str(REPORTS_DIR)), name="reports")
app.mount("/videos", StaticFiles(directory=str(VIDEO_DIR)), name="videos")

# WebSocket æ¥ç¶šç®¡ç†
active_connections: Dict[str, WebSocket] = {}


async def send_progress(session_id: str, stage: str, message: str, progress: int):
    """
    é€²æ—çŠ¶æ³ã‚’ WebSocket ã§é€ä¿¡
    
    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID
        stage: å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸ (transcription/audio_analysis/ai_analysis/report)
        message: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        progress: é€²æ—ç‡ (0-100)
    """
    if session_id in active_connections:
        try:
            await active_connections[session_id].send_json({
                "stage": stage,
                "message": message,
                "progress": progress,
                "timestamp": datetime.now().isoformat()
            })
        except Exception as e:
            logger.error(f"WebSocket é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            del active_connections[session_id]


@app.get("/", response_class=HTMLResponse)
async def index():
    """
    ç°¡æ˜“ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒ 
    """
    return """
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>åœ§å‹é¢æ¥ç·´ç¿’ã‚·ã‚¹ãƒ†ãƒ </title>
        <style>
            body {
                font-family: 'Segoe UI', sans-serif;
                max-width: 800px;
                margin: 50px auto;
                padding: 20px;
                background: #f5f5f5;
            }
            .container {
                background: white;
                padding: 40px;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            h1 {
                color: #333;
                margin-bottom: 30px;
            }
            .upload-area {
                border: 2px dashed #ccc;
                border-radius: 8px;
                padding: 40px;
                text-align: center;
                margin: 20px 0;
            }
            input[type="file"] {
                display: none;
            }
            .file-label {
                display: inline-block;
                padding: 12px 30px;
                background: #007bff;
                color: white;
                border-radius: 5px;
                cursor: pointer;
                transition: background 0.3s;
            }
            .file-label:hover {
                background: #0056b3;
            }
            button {
                width: 100%;
                padding: 15px;
                background: #28a745;
                color: white;
                border: none;
                border-radius: 5px;
                font-size: 16px;
                cursor: pointer;
                margin-top: 20px;
            }
            button:hover {
                background: #218838;
            }
            button:disabled {
                background: #ccc;
                cursor: not-allowed;
            }
            #status {
                margin-top: 20px;
                padding: 15px;
                border-radius: 5px;
                display: none;
            }
            .success { background: #d4edda; color: #155724; }
            .error { background: #f8d7da; color: #721c24; }
            .info { background: #d1ecf1; color: #0c5460; }
            #fileName {
                margin-top: 10px;
                color: #666;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¤ åœ§å‹é¢æ¥ç·´ç¿’ã‚·ã‚¹ãƒ†ãƒ </h1>
            <p>éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AI ãŒåˆ†æã—ã¾ã™ã€‚</p>
            
            <div style="margin: 20px 0; padding: 15px; background: #e3f2fd; border-radius: 8px; text-align: center;">
                <a href="/static/realtime.html" style="color: #1976d2; text-decoration: none; font-weight: bold; font-size: 1.1em;">
                    ğŸ™ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¢æ¥ç·´ç¿’ã‚’é–‹å§‹ â†’
                </a>
            </div>
            
            <form id="uploadForm" enctype="multipart/form-data">
                <div class="upload-area">
                    <label for="audioFile" class="file-label">
                        ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
                    </label>
                    <input type="file" id="audioFile" name="file" accept=".mp3,.wav,.m4a" required>
                    <div id="fileName"></div>
                </div>
                
                <button type="submit" id="submitBtn">
                    ğŸš€ åˆ†æé–‹å§‹
                </button>
            </form>
            
            <div id="progressContainer" style="display:none; margin-top: 20px;">
                <div style="margin-bottom: 10px;">
                    <strong id="currentStage">æº–å‚™ä¸­...</strong>
                </div>
                <div style="background: #e0e0e0; border-radius: 10px; overflow: hidden; height: 30px;">
                    <div id="progressBar" style="width: 0%; height: 100%; background: linear-gradient(90deg, #007bff, #0056b3); transition: width 0.3s; display: flex; align-items: center; justify-content: center; color: white; font-weight: bold;">
                        <span id="progressText">0%</span>
                    </div>
                </div>
                <div id="progressMessage" style="margin-top: 10px; color: #666; font-size: 14px;"></div>
            </div>
            
            <div id="status"></div>
        </div>

        <script>
            const form = document.getElementById('uploadForm');
            const fileInput = document.getElementById('audioFile');
            const fileName = document.getElementById('fileName');
            const status = document.getElementById('status');
            const submitBtn = document.getElementById('submitBtn');

            fileInput.addEventListener('change', (e) => {
                if (e.target.files.length > 0) {
                    fileName.textContent = `é¸æŠ: ${e.target.files[0].name}`;
                }
            });

            form.addEventListener('submit', async (e) => {
                e.preventDefault();
                
                const file = fileInput.files[0];
                if (!file) return;

                // ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID ç”Ÿæˆ
                const sessionId = Date.now().toString();

                // UI æ›´æ–°
                submitBtn.disabled = true;
                submitBtn.textContent = 'â³ åˆ†æä¸­...';
                status.style.display = 'none';
                const progressContainer = document.getElementById('progressContainer');
                progressContainer.style.display = 'block';

                // WebSocket æ¥ç¶š
                const ws = new WebSocket(`ws://${window.location.host}/ws/${sessionId}`);
                
                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    document.getElementById('currentStage').textContent = data.stage;
                    document.getElementById('progressBar').style.width = `${data.progress}%`;
                    document.getElementById('progressText').textContent = `${data.progress}%`;
                    document.getElementById('progressMessage').textContent = data.message;
                };

                ws.onerror = (error) => {
                    console.log('WebSocket ã‚¨ãƒ©ãƒ¼ï¼ˆé€²æ—è¡¨ç¤ºã®ã¿å½±éŸ¿ï¼‰:', error);
                };

                // FormData ä½œæˆ
                const formData = new FormData();
                formData.append('file', file);

                try {
                    const response = await fetch(`/api/analyze?session_id=${sessionId}`, {
                        method: 'POST',
                        body: formData
                    });

                    const result = await response.json();

                    if (response.ok) {
                        progressContainer.style.display = 'none';
                        status.style.display = 'block';
                        status.className = 'success';
                        status.innerHTML = `
                            âœ… åˆ†æå®Œäº†!<br>
                            <strong>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:</strong> ${result.summary.keywords.join(', ')}<br>
                            <strong>è©±é€Ÿ:</strong> ${result.summary.speech_rate} æ–‡å­—/åˆ†<br>
                            <a href="${result.report_url}" target="_blank" style="display: inline-block; margin-top: 10px; padding: 10px 20px; background: #007bff; color: white; text-decoration: none; border-radius: 5px;">ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ã</a>
                        `;
                        ws.close();
                    } else {
                        throw new Error(result.detail || 'åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ');
                    }
                } catch (error) {
                    progressContainer.style.display = 'none';
                    status.style.display = 'block';
                    status.className = 'error';
                    status.textContent = `âŒ ã‚¨ãƒ©ãƒ¼: ${error.message}`;
                    ws.close();
                } finally {
                    submitBtn.disabled = false;
                    submitBtn.textContent = 'ğŸš€ åˆ†æé–‹å§‹';
                }
            });
        </script>
    </body>
    </html>
    """


@app.post("/api/analyze")
async def analyze_interview(file: UploadFile = File(...)) -> Dict[str, Any]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€Markdown ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        file: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« (mp3/wav/m4a)
    
    Returns:
        ãƒ¬ãƒãƒ¼ãƒˆ URL ã¨åˆ†æçµæœã®ã‚µãƒãƒª
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        allowed_extensions = {".mp3", ".wav", ".m4a", ".ogg", ".flac"}
        file_ext = Path(file.filename).suffix.lower()
        
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚å¯¾å¿œå½¢å¼: {', '.join(allowed_extensions)}"
            )
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        audio_filename = f"{timestamp}_{file.filename}"
        audio_path = AUDIO_DIR / audio_filename
        
        logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜é–‹å§‹: {audio_filename}")
        
        with open(audio_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {audio_path} ({len(content)} bytes)")
        
        # === åˆ†æå‡¦ç† ===
        
        # 1. æ–‡å­—èµ·ã“ã—
        logger.info("æ–‡å­—èµ·ã“ã—é–‹å§‹...")
        transcript_result = transcribe_audio(str(audio_path))
        
        # 2. éŸ³éŸ¿åˆ†æ
        logger.info("éŸ³éŸ¿åˆ†æé–‹å§‹...")
        audio_features = analyze_audio_features(str(audio_path))
        
        # 3. éŸ³å£°æ„Ÿæƒ…åˆ†æ (å£°ã®éœ‡ãˆãƒ»ç·Šå¼µåº¦)
        logger.info("éŸ³å£°æ„Ÿæƒ…åˆ†æé–‹å§‹...")
        voice_emotion = analyze_voice_emotion(str(audio_path))
        emotion_feedback = get_emotion_feedback(voice_emotion)
        
        # 4. AI åˆ†æ
        logger.info("AI åˆ†æé–‹å§‹...")
        ai_analysis = analyze_with_gemini(
            transcript=transcript_result["text"],
            audio_features=audio_features
        )
        
        # 5. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        logger.info("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        report_filename = f"{timestamp}_report.md"
        report_path = REPORTS_DIR / report_filename
        
        generate_markdown_report(
            output_path=str(report_path),
            timestamp=timestamp,
            filename=file.filename,
            transcript=transcript_result,
            audio_features=audio_features,
            ai_analysis=ai_analysis,
            voice_emotion=voice_emotion,
            emotion_feedback=emotion_feedback
        )
        
        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        return {
            "status": "success",
            "report_url": f"/reports/{report_filename}",
            "report_path": str(report_path),
            "summary": {
                "transcript_length": len(transcript_result["text"]),
                "speech_rate": audio_features.get("speech_rate", 0),
                "keywords": ai_analysis.get("keywords", [])[:5],
                "confidence_score": voice_emotion.get("confidence_score", 0),
                "nervousness_score": voice_emotion.get("nervousness_score", 0)
            }
        }
        
    except Exception as e:
        logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@app.post("/api/video/analyze")
async def analyze_video_endpoint(file: UploadFile = File(...)) -> Dict[str, Any]:
    """
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚Šã€å°†æ¥ã®ãƒ“ãƒ‡ã‚ªåˆ†æå‡¦ç†ã¸é€£æºã™ã‚‹ãŸã‚ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ API

    Phase 4 ã§å®Ÿè£…äºˆå®šã® MediaPipe è§£æã«å‚™ãˆã€ç¾æ™‚ç‚¹ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã¨ã‚¹ã‚¿ãƒ–åˆ†æã®ã¿è¡Œã†ã€‚
    """
    try:
        allowed_extensions = {".mp4", ".mov", ".webm", ".mkv"}
        file_ext = Path(file.filename).suffix.lower()

        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å‹•ç”»å½¢å¼ã§ã™ã€‚å¯¾å¿œå½¢å¼: {', '.join(sorted(allowed_extensions))}"
            )

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        video_filename = f"{timestamp}_{file.filename}"
        video_path = VIDEO_DIR / video_filename

        logger.info(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜é–‹å§‹: {video_filename}")
        with open(video_path, "wb") as f:
            content = await file.read()
            f.write(content)
        logger.info(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {video_path} ({len(content)} bytes)")

        # Phase 4 äºˆå®šã®ãƒ“ãƒ‡ã‚ªåˆ†æã‚¹ã‚¿ãƒ–ã‚’å‘¼ã³å‡ºã—
        analysis_result = analyze_video(str(video_path))

        preview_url = f"/videos/{video_filename}"

        return {
            "status": "pending",
            "message": "ãƒ“ãƒ‡ã‚ªåˆ†æã¯ Phase 4 ã§æœ¬æ ¼å¯¾å¿œäºˆå®šã§ã™ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå‹•ç”»ã¯å®‰å…¨ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚",
            "preview_url": preview_url,
            "analysis": analysis_result,
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å‹•ç”»åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å‹•ç”»ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@app.get("/api/reports")
async def list_reports():
    """
    ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—
    """
    reports = []
    for report_file in REPORTS_DIR.glob("*.md"):
        reports.append({
            "filename": report_file.name,
            "url": f"/reports/{report_file.name}",
            "created_at": datetime.fromtimestamp(report_file.stat().st_mtime).isoformat()
        })
    
    reports.sort(key=lambda x: x["created_at"], reverse=True)
    return {"reports": reports, "total": len(reports)}


@app.get("/health")
async def health_check():
    """
    ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    """
    gemini_key = os.getenv("GEMINI_API_KEY", "")
    
    return {
        "status": "healthy",
        "gemini_configured": bool(gemini_key and gemini_key != "your_api_key_here"),
        "output_dir_exists": OUTPUT_DIR.exists(),
        "audio_dir_exists": AUDIO_DIR.exists(),
        "reports_dir_exists": REPORTS_DIR.exists()
    }


@app.websocket("/ws/realtime")
async def websocket_realtime_analysis(websocket: WebSocket):
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°åˆ†æWebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ ã‚µãƒ¼ãƒãƒ¼:
        { "type": "audio_chunk", "data": base64_encoded_audio }
        { "type": "end_session" }
    
    ã‚µãƒ¼ãƒãƒ¼ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ:
        { "type": "transcription", "text": "...", "accumulated_text": "..." }
        { "type": "analysis", "keywords": [...], "confidence_score": 75, ... }
        { "type": "final", "full_text": "...", "analysis": {...} }
    """
    await websocket.accept()
    session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    active_connections[session_id] = websocket
    
    transcriber = RealtimeTranscriber()
    
    logger.info(f"WebSocketæ¥ç¶šé–‹å§‹: {session_id}")
    
    try:
        await websocket.send_json({
            "type": "connected",
            "session_id": session_id,
            "message": "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æé–‹å§‹"
        })
        
        while True:
            try:
                # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡
                data = await websocket.receive_json()
                message_type = data.get("type")
                
                if message_type == "audio_chunk":
                    # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
                    import base64
                    audio_data = base64.b64decode(data.get("data", ""))
                    
                    # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                    transcriber.add_audio_chunk(audio_data)
                    
                    # ãƒãƒƒãƒ•ã‚¡ãŒä¸€å®šæ™‚é–“åˆ†è²¯ã¾ã£ãŸã‚‰æ–‡å­—èµ·ã“ã— + éŸ³éŸ¿ãƒ»æ„Ÿæƒ…åˆ†æ
                    if transcriber.get_buffer_duration() >= transcriber.buffer_duration:
                        result = await transcriber.process_buffer()
                        
                        if result.get("text"):
                            # æ–‡å­—èµ·ã“ã—çµæœé€ä¿¡
                            await websocket.send_json({
                                "type": "transcription",
                                "text": result["text"],
                                "accumulated_text": result["accumulated_text"],
                                "duration": result["duration"]
                            })
                            
                            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³éŸ¿åˆ†æé€ä¿¡
                            audio_features = result.get("audio_features", {})
                            if audio_features:
                                await websocket.send_json({
                                    "type": "audio_analysis",
                                    "speech_rate": audio_features.get("speech_rate", 0),
                                    "average_volume": audio_features.get("average_volume", 0),
                                    "max_volume": audio_features.get("max_volume", 0),
                                    "pause_count": audio_features.get("pause_count", 0),
                                    "average_pitch": audio_features.get("average_pitch", 0)
                                })
                            
                            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿæƒ…åˆ†æé€ä¿¡
                            voice_emotion = result.get("voice_emotion", {})
                            if voice_emotion:
                                await websocket.send_json({
                                    "type": "voice_emotion",
                                    "jitter": voice_emotion.get("jitter", 0),
                                    "pitch_variance": voice_emotion.get("pitch_variance", 0),
                                    "energy_variance": voice_emotion.get("energy_variance", 0),
                                    "confidence_score": voice_emotion.get("confidence_score", 0),
                                    "nervousness_score": voice_emotion.get("nervousness_score", 0),
                                    "feedback": voice_emotion.get("feedback", "")
                                })
                            
                            # ä¸€å®šé‡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒè²¯ã¾ã£ãŸã‚‰AIåˆ†æå®Ÿè¡Œ
                            if len(result["accumulated_text"]) > 100:
                                analysis = await transcriber.analyze_accumulated_text()
                                await websocket.send_json({
                                    "type": "analysis",
                                    **analysis
                                })
                
                elif message_type == "end_session":
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼šæ®‹ã‚Šã®å‡¦ç†
                    logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {session_id}")
                    
                    final_result = await transcriber.finalize()
                    final_analysis = await transcriber.analyze_accumulated_text()
                    
                    await websocket.send_json({
                        "type": "final",
                        "full_text": final_result["accumulated_text"],
                        "analysis": final_analysis
                    })
                    
                    break
                    
            except WebSocketDisconnect:
                logger.info(f"WebSocketåˆ‡æ–­: {session_id}")
                break
            except Exception as e:
                logger.error(f"WebSocketã‚¨ãƒ©ãƒ¼: {e}")
                await websocket.send_json({
                    "type": "error",
                    "message": str(e)
                })
                
    finally:
        # æ¥ç¶šã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if session_id in active_connections:
            del active_connections[session_id]
        logger.info(f"WebSocketæ¥ç¶šçµ‚äº†: {session_id}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)


@app.websocket("/ws/live-analysis/{session_id}")
async def websocket_live_analysis(websocket: WebSocket, session_id: str):
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°+æ˜ åƒåˆ†æWebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ ã‚µãƒ¼ãƒãƒ¼:
        { "type": "audio", "data": base64_audio_chunk }
        { "type": "video", "data": base64_video_frame }
        { "type": "stop" }
    
    ã‚µãƒ¼ãƒãƒ¼ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ:
        { "type": "audio_analysis", "transcription": "...", "emotion": {...}, "audio_level": 75 }
        { "type": "video_analysis", "posture": {...}, "eye_contact": {...} }
        { "type": "summary", ... }
    """
    await websocket.accept()
    active_connections[session_id] = websocket
    
    session_recorder = SessionRecorder(session_id, SESSIONS_DIR)
    analyzer = RealtimeAnalyzer(session_id, recorder=session_recorder)
    logger.info(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æé–‹å§‹: {session_id}")
    
    try:
        await websocket.send_json({
            "type": "connected",
            "session_id": session_id,
            "message": "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†ææº–å‚™å®Œäº†"
        })
        
        while True:
            try:
                data = await websocket.receive_json()
                message_type = data.get("type")
                
                if message_type == "audio":
                    # éŸ³å£°ãƒãƒ£ãƒ³ã‚¯åˆ†æ
                    import base64
                    audio_bytes = base64.b64decode(data.get("data", ""))
                    result = await analyzer.analyze_audio_chunk(audio_bytes)
                    await websocket.send_json(result)
                    
                elif message_type == "video":
                    # æ˜ åƒãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
                    import base64
                    frame_bytes = base64.b64decode(data.get("data", ""))
                    result = await analyzer.analyze_video_frame(frame_bytes)
                    await websocket.send_json(result)
                    
                elif message_type == "stop":
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼šã‚µãƒãƒªãƒ¼ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                    logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†: {session_id}")
                    
                    recording_info = await analyzer.finalize_session()
                    summary = await analyzer.get_summary()
                    await websocket.send_json(summary)

                    await websocket.send_json({
                        "type": "processing",
                        "message": "éŒ²ç”»ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¦ã„ã¾ã™..."
                    })

                    try:
                        report_info = await run_post_session_pipeline(session_id, recording_info, REPORTS_DIR)
                        await websocket.send_json({
                            "type": "report_ready",
                            "report_url": report_info["report_url"],
                            "report_path": report_info["report_path"],
                            "video_analysis": report_info.get("video"),
                            "message": "ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ"
                        })
                        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_info['report_path']}")
                    except Exception as e:
                        logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                        await websocket.send_json({
                            "type": "error",
                            "message": f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
                        })
                    
                    break
                    
            except WebSocketDisconnect:
                logger.info(f"WebSocketåˆ‡æ–­: {session_id}")
                break
            except Exception as e:
                logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                await websocket.send_json({
                    "type": "error",
                    "message": str(e)
                })
                
    finally:
        if session_id in active_connections:
            del active_connections[session_id]
        await analyzer.finalize_session()
        logger.info(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æçµ‚äº†: {session_id}")

