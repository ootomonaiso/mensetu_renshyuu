# デジタル学園祭 第３回「全国情報教育コンテスト」応募用紙

## 基本情報

- **作品タイトル**: 圧勝面接
- **チーム名**: ASKSTEM
- **応募代表者名**: [記入が必要]
- **チームメンバー**: [記入が必要]

---

## 1. 作品概要

### ①一言キャッチ

AI音声分析で面接力を可視化し、教師と生徒の練習を支援する完全無料ツール

### ②解決したい課題

面接練習において、教師が生徒の話し方や表現力を客観的に評価・フィードバックすることが困難で、改善ポイントが主観的になりやすい。

### ③主な利用者（ターゲット）

- 高校・大学の進路指導教員
- 就職・受験を控えた生徒・学生
- 面接練習をサポートする保護者

### ④作品の仕組み

```
[録音] → [話者分離] → [文字起こし] → [AI補正] → [音声分析] → [レポート生成]
```

1. **録音**: ブラウザから教師と生徒の面接練習を録音
2. **話者分離**: pyannote.audioで話者を自動識別（教師/生徒）
3. **文字起こし**: OpenAI Whisperで日本語音声をテキスト化
4. **AI補正**: Ollama (Llama 3.2)で文法・敬語をチェック
5. **音声分析**: librosaでピッチ、音量、話速、声のトーンを分析
6. **レポート生成**: 分析結果をHTML/PDFで出力

### ⑤使用した主な技術

**使用した技術**:
- プログラムやアプリを作った（FastAPI, Python）
- 外部サービスやAPIと連携した（Ollama API）
- センサーで情報を集めた（マイク入力による音声取得）
- クラウド上でデータやプログラムを動かした（Webアプリケーション）
- Webサイトを公開した（Webベースのインターフェース）
- データを分析・可視化した（音声の特徴量抽出、グラフ化）

**AIの利用内容**:
- 音声をAIで処理した（音声→文字、話者分離）
- 文章をAIで作った（文法・敬語の修正提案）
- 既存のAIサービスを利用した（OpenAI Whisper, pyannote.audio, Ollama）
- マイクやセンサーのデータをAIで分析した（声の特徴分析、感情推定）

### ⑥特に工夫した点

- **完全無料・プライバシー保護**: API料金ゼロで完全ローカル実行。録音データは外部送信せず、生徒のプライバシーを完全保護
- **多角的な音声分析**: 単なる文字起こしだけでなく、ピッチ（声の高さ）、音量、話速、声のトーン、感情（自信度・緊張度）を数値化
- **使いやすいUI**: ブラウザだけで完結し、専門知識不要で誰でも使える
- **オフライン動作**: 初回セットアップ後はインターネット接続不要で利用可能

### ⑦想定される効果・利用シーン

**利用シーン**:
- 放課後の面接練習で即座にフィードバック
- 自宅での自主練習で客観的な改善点を把握
- 複数回の練習で成長の過程を可視化

**期待される効果**:
- 教師の主観的な評価を客観データで補完
- 生徒が具体的な改善ポイントを理解し、自信を持って本番に臨める
- 繰り返し練習することで、声の出し方や話し方が自然に改善

---

## 2. 作品詳細①（課題・背景）

### 取り組む課題

面接練習において、教師が生徒の「話し方」「声のトーン」「敬語の使い方」を客観的に評価し、具体的なフィードバックを提供することが困難。生徒も自分の改善点を把握しづらい。

### 課題の背景・現状

- 面接練習は教師の主観的な評価に依存しがちで、「もっと自信を持って」「はっきり話して」など抽象的な指摘が多い
- 生徒は録音を聞き返しても、どこをどう改善すべきか分からない
- 教師の負担が大きく、全員に十分な時間をかけられない
- 外部の面接対策サービスは高額で、すべての生徒が利用できない

### 課題の重要性

就職・受験において面接は合否を左右する重要な要素。しかし、十分な練習とフィードバックを受けられないまま本番を迎える生徒が多い。特に地方校や経済的に厳しい家庭の生徒は、面接対策の機会が限られている。

### 課題構造の整理

- **誰が困っている**: 進路指導教員、生徒・学生
- **どんなことで困っている**: 主観的で抽象的なフィードバックしか提供できない、改善点が分からない
- **原因**: 
  - 音声の客観的な分析ツールがない
  - 教師の時間が限られている
  - 有料サービスは高額で利用しづらい
- **影響**: 
  - 生徒が自信を持てずに本番に臨む
  - 面接での評価が低くなる可能性
  - 教員の負担増加
- **解決手法**: 
  - AI技術で音声を客観的に分析
  - 完全無料で誰でも利用可能
  - レポート自動生成で教師の負担軽減

---

## 3. 作品詳細②（利用シーンと価値）

### どんな場面でどんな人が使うのか（利用シーン）

1. **放課後の面接練習**: 教師と生徒が1対1で面接練習を行い、終了後すぐにレポートを確認
2. **自宅での自主練習**: 生徒が家族と練習し、自分で分析結果を確認して改善
3. **複数回の練習での進捗確認**: 過去のレポートと比較して、成長を実感

### この作品を使うことでどんな良い効果が生まれるのか（価値創出）

- **客観的なフィードバック**: 「声の高さが低い」「話速が速すぎる」など数値で明確に
- **具体的な改善点**: 「敬語の使い方に3か所ミス」など改善箇所が明確
- **自信の向上**: 練習を重ねることで数値が改善し、生徒が成長を実感できる
- **教師の負担軽減**: 自動レポート生成により、フィードバック作成時間を削減
- **平等な機会**: 無料で誰でも利用でき、経済格差による機会格差を解消

### ほかの場面や人に広げられるか（波及効果）

- **企業の採用担当**: 新入社員研修での面接官トレーニング
- **スピーチ練習**: プレゼンテーションやスピーチの練習
- **言語学習**: 日本語学習者の発音・イントネーション練習
- **営業トレーニング**: 営業トークの練習とフィードバック
- **オンライン教育**: 遠隔地の生徒にも平等な面接対策を提供

### 安心して使えるように工夫している点（社会受容性）

- **プライバシー保護**: 録音データは完全ローカル保存、外部送信なし
- **操作の簡単さ**: ブラウザから録音ボタンを押すだけ、専門知識不要
- **無料**: API料金やサブスクリプション費用が一切不要
- **透明性**: すべての分析ロジックがオープンソースで公開
- **誤分析への対応**: AIの提案はあくまで参考情報として提示し、最終判断は人間が行う

---

## 4. 作品詳細③（開発概要）

### 作品の目的（何を達成したい？）

面接練習において、AIによる客観的な音声分析とフィードバックを提供し、生徒が自信を持って本番に臨めるようにする。同時に、教師の負担を軽減し、より多くの生徒に質の高い面接対策を提供できる環境を実現する。

### 全体のしくみ（どう動く？）

```
[入力] Webブラウザで録音ボタンをクリック → マイクから音声を収録
       ↓
[処理] ① 話者分離（pyannote.audio）: 教師と生徒の音声を自動識別
       ② 文字起こし（Whisper）: 音声をテキストに変換
       ③ AI補正（Ollama）: 文法・敬語の誤りをチェック
       ④ 音声分析（librosa）: ピッチ、音量、話速、感情を数値化
       ⑤ レポート生成（FPDF）: 分析結果をHTML/PDFにまとめる
       ↓
[出力] ブラウザにレポートを表示、PDF/HTMLでダウンロード可能
```

### 主な機能（この作品ができること）

1. **音声録音**: ブラウザから直接マイク入力で録音
2. **話者識別**: 教師と生徒の音声を自動で区別
3. **文字起こし**: 日本語音声を高精度でテキスト化
4. **日本語補正**: 敬語の誤り、文法ミスを指摘
5. **音声分析**: 
   - 平均ピッチ（声の高さ）
   - 音量レベル
   - 話速（1分あたりの文字数）
   - 声のトーン
   - 感情分析（自信度、緊張度、落ち着き度）
6. **レポート出力**: HTML/PDF形式で保存可能

### 技術のポイント（使っている技術・ツール）

- **フレームワーク**: FastAPI（高速なWebフレームワーク）
- **話者分離**: pyannote.audio（最先端の話者分離AI）
- **文字起こし**: OpenAI Whisper（高精度な音声認識）
- **AI補正**: Ollama + Llama 3.2（ローカルで動作するLLM）
- **音声分析**: librosa（音声特徴量抽出ライブラリ）
- **データベース**: SQLAlchemy（面接履歴の管理）
- **レポート生成**: FPDF2、matplotlib（PDF生成、グラフ可視化）

### 工夫した点・独自のポイント（新しさや差別化）

- **完全無料**: 一般的な音声分析サービスは有料だが、本作品は完全無料
- **プライバシー優先**: クラウドAPIを使わず、すべてローカル処理
- **多角的分析**: 単なる文字起こしだけでなく、感情分析や声質分析まで実施
- **教育特化**: 面接練習に特化した分析項目（敬語チェック、話速、自信度など）
- **使いやすさ**: 専門知識なしでブラウザから簡単に利用可能

---

## 5. 作品詳細④（システム構成図）

### システム構成図

```
┌─────────────────────────────────────────────────────────────┐
│                         ユーザー                              │
│                    （教師・生徒）                             │
└────────────────┬────────────────────────────────────────────┘
                 │
                 │ ブラウザでアクセス
                 ↓
┌─────────────────────────────────────────────────────────────┐
│                    Webインターフェース                         │
│               （HTML/CSS/JavaScript）                        │
│  ・録音開始/停止ボタン                                         │
│  ・ファイルアップロード                                         │
│  ・レポート表示                                                │
└────────────────┬────────────────────────────────────────────┘
                 │
                 │ HTTP POST（音声ファイル）
                 ↓
┌─────────────────────────────────────────────────────────────┐
│                FastAPIバックエンド（app.py）                   │
│  ・ルーティング処理                                            │
│  ・ファイル管理                                                │
│  ・各モジュール呼び出し                                         │
└────────────────┬────────────────────────────────────────────┘
                 │
    ┌────────────┼────────────┬────────────┬──────────────┐
    │            │            │            │              │
    ↓            ↓            ↓            ↓              ↓
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌──────────┐ ┌──────────┐
│話者分離  │ │文字起こし│ │AI補正    │ │音声分析   │ │レポート  │
│pyannote │ │Whisper  │ │Ollama   │ │librosa   │ │生成      │
│.audio   │ │         │ │Llama3.2 │ │          │ │FPDF2     │
└─────────┘ └─────────┘ └─────────┘ └──────────┘ └──────────┘
    │            │            │            │              │
    └────────────┴────────────┴────────────┴──────────────┘
                               │
                               ↓
                    ┌────────────────────┐
                    │   データベース      │
                    │   （SQLAlchemy）   │
                    │  ・面接履歴管理    │
                    └────────────────────┘
                               │
                               ↓
                    ┌────────────────────┐
                    │   ファイル保存      │
                    │ ・音声ファイル      │
                    │ ・HTMLレポート      │
                    │ ・PDFレポート       │
                    └────────────────────┘
```

---

## 6. 作品詳細⑤（処理の流れ）

### アルゴリズム（処理の流れ）

```
1. [録音開始]
   ↓
   - ユーザーがブラウザで「録音開始」ボタンをクリック
   - JavaScript経由でマイク入力を取得
   ↓
2. [録音中]
   ↓
   - 音声データをリアルタイムで収集
   - 録音時間を表示
   ↓
3. [録音停止]
   ↓
   - ユーザーが「停止」ボタンをクリック
   - 音声データをWAVファイルとして保存
   ↓
4. [アップロード]
   ↓
   - ファイルをサーバーに送信（HTTP POST）
   - サーバー側でファイルを保存
   ↓
5. [話者分離処理]
   ↓
   - pyannote.audioで音声を解析
   - 話者ごとにタイムスタンプを記録
   - 条件分岐: 話者が2人以上検出されたか？
     - YES → 教師/生徒として区別
     - NO → 警告を表示、処理継続
   ↓
6. [文字起こし処理]
   ↓
   - 話者ごとにセグメント分割
   - 各セグメントをWhisperで文字起こし
   - 繰り返し: すべてのセグメントを処理
   ↓
7. [AI補正処理]
   ↓
   - 文字起こしテキストをOllamaに送信
   - 敬語・文法の誤りをチェック
   - 修正提案を取得
   ↓
8. [音声分析処理]
   ↓
   - librosaで各セグメントの音声特徴を抽出:
     - ピッチ（平均、標準偏差）
     - 音量（RMS）
     - 話速（文字数 / 時間）
     - ゼロ交差率（緊張度）
     - スペクトル重心（自信度）
   - 話者ごとに統計情報を計算
   ↓
9. [レポート生成]
   ↓
   - 分析結果をまとめたHTMLを生成
   - グラフ画像を作成（matplotlib）
   - PDFを生成（FPDF2）
   ↓
10. [結果表示]
    ↓
    - ブラウザにレポートを表示
    - ダウンロードリンクを提供
    ↓
   [完了]
```

### ソースコード格納先

GitHub: https://github.com/ootomonaiso/mensetu_renshyuu

---

## 7. 作品詳細⑥（作品の形）

### 作品の形（UI・見た目・全体の構造）

**メイン画面**:
- シンプルなWebインターフェース
- 「録音開始」「停止」ボタン
- またはファイルアップロード機能
- 処理状況の表示（プログレスバー）

**レポート画面**:
- 話者別の文字起こしテキスト
- 敬語・文法の修正提案（赤字で表示）
- 音声分析結果のグラフ:
  - ピッチの時系列変化
  - 音量の推移
  - 感情スコア（レーダーチャート）
- 話者別の統計サマリー（表形式）
- PDF/HTMLダウンロードボタン

**技術スタック**:
- フロントエンド: HTML5, CSS3, JavaScript
- バックエンド: Python 3.9+, FastAPI
- 実行環境: ローカルPC（Windows/Mac/Linux）

※デモ動画リンク: [作成予定]

---

## 8. 作品詳細⑦（使いやすさと見せ方の工夫）

### 使いやすさと見せ方の工夫

1. **専門知識不要**: 
   - インストール後はブラウザから「録音開始」を押すだけ
   - 複雑な設定やパラメータ調整は不要

2. **視覚的なフィードバック**:
   - グラフで直感的に理解できる（話速、ピッチ、音量）
   - 色分けで改善点を強調（赤=要改善、緑=良好）

3. **段階的な情報提示**:
   - まず全体サマリーを表示
   - 詳細が見たい部分はクリックで展開

4. **初心者でも安心**:
   - ツールチップで各指標の意味を説明
   - 「この数値はどうすれば改善できる?」のヒントを表示

5. **アクセシビリティ**:
   - 画面リーダー対応
   - キーボード操作のみでも利用可能

6. **モバイル対応**:
   - レスポンシブデザインでスマホからも閲覧可能

---

## 9. 作品詳細⑧（探究のプロセス）

### 最初の「もやもや」はどんなものでしたか？

「面接練習で先生に『もっと自信を持って話して』と言われるけど、具体的に何をどう改善すればいいのか分からない…」という友人の悩みを聞いたことがきっかけ。主観的なフィードバックだけでは、具体的な改善が難しいと感じた。

### 調べたこと・試してみたことはなんですか？

1. **市場調査**: 
   - 既存の面接対策サービスを調査 → 高額（月額5000円〜）
   - 音声分析アプリ → 英語のみ、または機能が限定的

2. **技術検証**:
   - OpenAI Whisperで日本語文字起こしの精度をテスト → 高精度
   - pyannote.audioで話者分離を試行 → 2人の話者を明確に区別可能
   - Ollamaでローカル動作を確認 → API料金ゼロで実現可能

3. **ユーザーテスト**:
   - 教師と生徒に試用してもらい、フィードバックを収集
   - 「敬語チェックが役立つ」「グラフが分かりやすい」という声

### 得られた気づき（変化の瞬間）

- **予想外の発見**: 音量やピッチだけでなく、「緊張度」や「自信度」も音声から推定できることが分かった
- **ニーズの再発見**: 教師からも「評価の根拠を示せる」と好評で、生徒だけでなく教師側の課題も解決できると気づいた
- **技術の民主化**: 高額なサービスを使わなくても、オープンソースAIで十分な精度が出せることを確認

### 問いがどう変わったか

**最初の問い**: 「面接練習をどう改善するか？」

**今の問い**: 「どうすれば誰もが無料で、プライバシーを守りながら、質の高い面接対策を受けられるか？」

### 次にやってみたいこと

1. **リアルタイムフィードバック**: 練習中にリアルタイムで改善点を表示
2. **模擬面接AI**: AIが面接官役となり、質問 → 回答 → フィードバックの自動化
3. **長期的な進捗追跡**: 複数回の練習データを蓄積し、成長曲線を可視化
4. **多言語対応**: 英語面接やその他の言語にも対応
5. **コミュニティ機能**: ユーザー同士で面接練習のベストプラクティスを共有

---

## 10. 作品詳細⑨（倫理・法的遵守）

### 個人情報やプライバシーへの配慮

- **完全ローカル処理**: 録音データは一切外部サーバーに送信せず、ユーザーのPC内のみで処理
- **データの自動削除オプション**: レポート生成後、元の音声ファイルを自動削除する設定を提供
- **匿名化**: レポートには話者名を含めず、「教師」「生徒」とのみ表示
- **利用規約の明示**: 初回起動時にプライバシーポリシーを表示し、同意を得る

### 著作権・ライセンスの扱い

- **オープンソース**: 本作品はMITライセンスで公開
- **使用ライブラリ**: すべてオープンソースライセンス（MIT, Apache 2.0）に準拠
- **モデルの利用許諾**: 
  - OpenAI Whisper: MITライセンス
  - pyannote.audio: MITライセンス（HuggingFaceトークンが必要）
  - Llama 3.2: Metaのコミュニティライセンス（商用利用可）

### データの扱い（安全性）

- **暗号化**: データベース内の面接履歴はAES-256で暗号化
- **アクセス制限**: ローカルホスト（127.0.0.1）のみアクセス可能、外部からの接続を拒否
- **定期的なクリーンアップ**: 古い録音ファイル（30日以上）は自動削除を推奨
- **バックアップ**: ユーザーが手動でバックアップを取得可能

### AI・センサー等を使う場合の倫理配慮

- **バイアスへの対応**: 
  - 特定の方言や声質を不当に低く評価しないよう、分析結果に「参考値」と明記
  - 性別・年齢による評価の偏りを排除
- **誤認識への対応**: 
  - AIの判断は「提案」として提示し、最終判断は人間が行う
  - 誤字脱字の可能性を明示（「Whisperによる自動文字起こしのため、誤りがある可能性があります」）
- **透明性**: 
  - すべての分析ロジックをGitHubで公開し、どのように評価されているかを明示
- **検証機能**: 
  - ユーザーが「この評価はおかしい」とフィードバックできる機能を実装予定

### 利用者や社会にとって安心できる工夫

- **説明可能性**: 各評価項目について「なぜこの数値になったか」を説明
- **誤操作防止**: 「録音開始」ボタンは確認ダイアログを表示
- **心理的負担の軽減**: 「評価」ではなく「改善提案」としてポジティブに表現
- **監視されている感を排除**: 録音は明示的に開始/停止する必要があり、無断録音は不可
- **社会的影響**: 経済格差による教育格差を解消し、すべての生徒に平等な機会を提供

---

## 提出チェックリスト

- [x] 作品タイトル・チーム名を記載
- [ ] 応募代表者名・チームメンバーを記載 ※要記入
- [x] ①〜⑦の作品概要をすべて記載
- [x] 課題・背景を記載
- [x] 利用シーンと価値を記載
- [x] 開発概要を記載
- [x] システム構成図を記載
- [x] 処理の流れ（アルゴリズム）を記載
- [x] 作品の形（UI）を記載
- [x] 使いやすさの工夫を記載
- [x] 探究のプロセスを記載
- [x] 倫理・法的遵守を記載

---

**作成日**: 2025年12月20日
**プロジェクト**: 圧勝面接 (mensetu_renshyuu)
**GitHub**: https://github.com/ootomonaiso/mensetu_renshyuu
